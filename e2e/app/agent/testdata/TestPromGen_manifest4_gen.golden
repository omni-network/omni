global:
  scrape_interval: 30s # Set the scrape interval to every 30 seconds.
  evaluation_interval: 30s # Evaluate rules every 30 seconds.
remote_write:
  - url: https://grafana.com
    basic_auth:
      username: admin
      password: password
    write_relabel_configs:
      # Add 'container' label using 'instance without port'
      - source_labels: [instance]
        regex: '(.+):(\d+)'
        target_label: container
        replacement: '${1}'


scrape_configs:
  - job_name: "halo"
    metrics_path: "/metrics"
    static_configs:
      - targets: [validator01:26660,validator02:26660,fullnode03:26660] # halo targets
        labels:
          network: 'staging'
          host: 'vm'

  - job_name: "geth"
    metrics_path: "/debug/metrics/prometheus"
    static_configs:
      - targets: [] # geth targets
        labels:
          network: 'staging'
          host: 'vm'

  - job_name: "relayer"
    metrics_path: "/metrics"
    static_configs:
      - targets: [relayer:26660] # relayer targets
        labels:
          network: 'staging'
          host: 'vm'

  - job_name: "monitor"
    metrics_path: "/metrics"
    static_configs:
      - targets: [monitor:26660] # monitor targets
        labels:
          network: 'staging'
          host: 'vm'

  - job_name: "explorer_indexer"
    metrics_path: "/metrics"
    static_configs:
      - targets: [explorer_indexer:26660] # explorer_indexer targets
        labels:
          network: 'staging'
          host: 'vm'

  - job_name: "explorer_graphql"
    metrics_path: "/metrics"
    static_configs:
      - targets: [explorer_graphql:26660] # explorer_graphql targets
        labels:
          network: 'staging'
          host: 'vm'

